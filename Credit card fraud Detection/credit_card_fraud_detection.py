# -*- coding: utf-8 -*-
"""Credit_Cadr_Fraud_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AqV7Hp6mAv5N6k2qeV0465tMg91XLTHe
"""

from google.colab import drive
drive.mount('/content/drive')



"""## **Importing required edpendencies**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

data = '/content/drive/MyDrive/Colab Notebooks/0. Projects/Machine Learning Projects/Credit Card Fraud detection/creditcard.csv'

df = pd.read_csv(data)

df.head()

df.tail()

df.info()

# checking the number of missing value i clumns
df.isnull().sum()

"""## **Checking the number of Legit and Fraudulent Transaction**

- Legit Transaction = 0
- Fraudulent Transaction = 1
"""

#  distribution of legit transaction and fraudulent transaction
df['Class'].value_counts()

"""## **Converting Imbalence data into balance data**

- 0 --> Normal Transaction
- 1 --> Fraudelent Transaction
"""

# Seperating the data for analysis

legit = df[df.Class == 0]
fraud = df[df.Class == 1]

print(legit.shape)
print(fraud.shape)

# Observation
    # -> here we assign proper lable to class data.
    # Class(0) = Legit transaction
    # Class(1) = Fraudulent transaction

"""## **Displaying the Statistical data for class**"""

legit.Amount.describe()

fraud.Amount.describe()

# Observation
  # --> The count of legit data is more than fraud data.
  #  --> The mean amount of fraud data is more than the mean amount of legit data
  # --> The max amount of legit transaction is 25691.16 dollers.
  # --> The max amount of fraud transaction is 2125.87 dollers.

#  Compare the values for both transaction

df.groupby('Class').mean()

class_counts = df['Class'].value_counts()
class_labels = ['legit','fraud']
plt.figure(figsize=(6,4))
class_counts.plot(kind='bar', color=['skyblue', 'orange'])
plt.title('Class Distribution')
plt.xticks(ticks=[0, 1], labels=class_labels, rotation=0)
plt.ylabel('Count')
plt.legend(['legit', 'fraud'])
plt.show()

"""## **Under-Sampling**

- Randomly selecting the data from legit transaction and make it equals to fraudulent transaction.

- Through this process we create normally distributed data that make better prediction in Machine Learning.


Number of Fradulent transaction = 492
"""

legit_sample = legit.sample(n=492)

# n= 492 becoz the numbe of fradulent transaction is 492 and we want to make it equals to Normal Transaction.

print(legit_sample.shape)
print(fraud.shape)

"""## **Concatinating the DataFrame**"""

new_df = pd.concat([legit_sample, fraud], axis = 0)

new_df

new_df['Class'].value_counts()

new_df.groupby('Class').mean()

class_counts = df['Class'].value_counts()
class_labels = ['legit_sample','fraud']
plt.figure(figsize=(6,4))
class_counts.plot(kind='bar', color=['skyblue', 'green'])
plt.title('New Class Distribution')
plt.xticks(ticks=[0, 1], labels=class_labels, rotation=0)
plt.ylabel('Count')
plt.legend(['legit', 'fraud'])
plt.show()

"""## **Splitting the data into Features and Target**"""

X = new_df.drop(columns = 'Class', axis = 1)
y = new_df['Class']

print(X)

print(y)



"""## **Splitting the Data into Trainign and Testing**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2, stratify = y)

# stratify = y --> evenly distribute the target data

   # input training data is stored in X_train
   # corresponding output training data is stored in y_train
   # input testing data is stored in X_test
   # corresponding output testing data is stored in y_test

print(X.shape, X_train.shape, X_test.shape)



"""## **Model Training**"""

log_reg = LogisticRegression()
# train the data
log_reg.fit(X_train, y_train)

"""## **Evaluation of Model**

Accuracy Score of Training Data
"""

X_train_pred = log_reg.predict(X_train)
training_data_accuracy = accuracy_score(X_train_pred, y_train)

print("The accuracy score of training data is : ",training_data_accuracy)

"""Accuracy Score of Testing Data"""

X_test_pred = log_reg.predict(X_test)
testing_data_accuracy = accuracy_score(X_test_pred, y_test)

print("The accuracy score of training data is : ",testing_data_accuracy)

